{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from models import InferSent\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements={'sc':['rel','md','reqd','reld','ofc','immed','fwdd','wk','agn','cust','eowk','eow','eod','inv','emd','md','ck','chk','po','p o','sched','pd','pmt','pymt','pymnt','amt','rcvd','recieved','rec','recd',\"recd\"],\n",
    "             'ff':['released','mailed','required','released','ofcourse','immediately','forwarded','week','again','customer','date','date','time','invoice','mailed','mailed','check','check','purchase order','purchase order','scheduled','paid','payment','payment','payment','amount','received','received','received','received','received']}\n",
    "replacements=dict(zip(replacements['sc'],replacements['ff']))\n",
    "\n",
    "def replace(text):\n",
    "    text = re.sub(r'\\'', '', text)\n",
    "    #print(text)\n",
    "    words=nltk.word_tokenize(text)\n",
    "    words= [w if  w not in replacements.keys() else replacements[w] for w in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'received'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace(\"rec'd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spell(text):\n",
    "    words=nltk.word_tokenize(text)\n",
    "    #print(type(words))\n",
    "    i=0\n",
    "    for word in words:\n",
    "        #print(word)\n",
    "        misspelled = spell.unknown([word])\n",
    "        #print(i, word)\n",
    "        #print(len(misspelled))\n",
    "        for word in misspelled:\n",
    "            #print(\"Inside 2nd for loop\")\n",
    "            words[i]=spell.correction(word)\n",
    "            #print(spell.correction(word))\n",
    "        i=i+1\n",
    "    return ' '.join(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My ndme received S\n",
      "My name received S\n"
     ]
    }
   ],
   "source": [
    "rep=replace(\"My ndme rec'd S\")\n",
    "print(rep)\n",
    "print(correct_spell(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=re.sub(r'\\s+', ' ', text)\n",
    "    text=text.lower()\n",
    "    text=re.sub(r'(\\d+/\\d+/\\d+)|(\\d+\\.\\d+\\.\\d+)|(\\d+\\-\\d+\\-\\d+)|(\\d+\\/\\d+)|(\\d+th)|(\\d+nd)|(\\d+rd)|(\\d+st)', ' DATE ', text)\n",
    "    text=re.sub(r'\\b(mon|tue|wed|thurs|fri|sat|sun|monday|tuesday|wednesday|thursday|friday|saturday|sunday|jan|feb|mar|apr|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|june|july|august|september|october|november|december)\\b',' DATE ', text)\n",
    "    text=re.sub(r'(\\$\\d+\\,\\d+\\.\\d+)|(\\$\\d+\\,\\d+)|(\\$\\d+\\.\\d+)|(\\$\\d+)|(\\$\\ d+\\,\\d+\\.\\d+)|(\\$ \\d+\\,\\d+)|(\\$ \\d+\\.\\d+)|(\\$ \\d+)|(\\d+\\,\\d+\\.\\d+)|(\\d+\\,\\d+)|(\\d+\\.\\d+)', ' AMOUNT ', text)\n",
    "    text=re.sub(r'(#\\d+)|(# \\d+)|(\\d+)', ' NUMBER ', text)\n",
    "    text=re.sub(r'(\\d+\\.\\d+)|(\\d+)', ' AMOUNT ', text)\n",
    "    text=re.sub(r'[^\\s]+@[^\\s]+\\.[^\\s]+',' MAIL ', text)\n",
    "    text=re.sub(r'\\s+', ' ', text)\n",
    "    text=re.sub(r'(\\()|(\\))', '', text)\n",
    "    text=re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text=re.sub(r'\\s+', ' ', text)\n",
    "    text=text.lower()\n",
    "    text=replace(text)\n",
    "    text=correct_spell(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(lines):\n",
    "    final_lines = list()\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        text = clean_text(line)\n",
    "        #print(text)\n",
    "        final_lines.append(text)\n",
    "    return final_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/NLP/Data/labelled_transcripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sentence', 'label'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             Hello, this is John Smith.\n",
       "1                                    Hi, this is Amanda.\n",
       "2                                           How are you?\n",
       "3                                              I'm fine.\n",
       "4                                           How are you?\n",
       "5                                             I am good.\n",
       "6           Actually I'm able to see transcript as well.\n",
       "7                                           Okay, great.\n",
       "8                                     Either timing out.\n",
       "9      Like what time is over but I don't know at lea...\n",
       "10                                                 Okay.\n",
       "11                          Can you check that our dogs?\n",
       "13       Just going to call and and make the call again.\n",
       "14                Now you won't be able to see anything.\n",
       "15                                                 Kesha\n",
       "16     Hello, this is Faith here if Isaac David from ...\n",
       "17                                    How are you doing?\n",
       "18                                          Doing great.\n",
       "19                                       It's late here.\n",
       "20                                            What's up?\n",
       "22                                          I see I see.\n",
       "23     So what delay payments are we talking about here?\n",
       "26                                                I see.\n",
       "27                                        You know what?\n",
       "29     Can I just expect it to be like me just bring ...\n",
       "31                      I would say let's let's call it.\n",
       "34                                  That's fine with me.\n",
       "35                                                 Okay.\n",
       "36                                         Thanks a lot.\n",
       "37                        So it was nice talking to you.\n",
       "                             ...                        \n",
       "825    I'm in behalf not being we didn't get the righ...\n",
       "826    We were informed or bottom of the same, but it...\n",
       "827                                         Let us know.\n",
       "828    I know you're busy we have been thinking of is...\n",
       "831    Just let me know home Biggby already contacted...\n",
       "832                                      We can do that.\n",
       "833                                                Okay.\n",
       "834                                                 Bye.\n",
       "835                                                 Bye.\n",
       "836                                    So so yeah, okay.\n",
       "837                                        Thanks a lot.\n",
       "838                                                 Bye.\n",
       "839                                                 Bye.\n",
       "840           Hey John, this is David from APC products.\n",
       "841                                   How are you doing?\n",
       "844                                        Thanks a lot.\n",
       "845    Joe John, thanks a lot for information in writ...\n",
       "846                                                 Bye.\n",
       "847                                                 Bye.\n",
       "848      Hi, this is Aunt this already seriously past...\n",
       "850                         Can you make the commitment?\n",
       "851    Yes, I really appreciate the consideration thi...\n",
       "852    Let's make sure all the information is correct...\n",
       "854                                               Right?\n",
       "856    Can you tell me when the malls that Romney sty...\n",
       "857                             Yes, that's what I have.\n",
       "858    I told you we are getting back on our feet so ...\n",
       "861                          Thanks for working with us.\n",
       "862    Just keep talking to us and keep your commitme...\n",
       "863                                    Have a great day.\n",
       "Name: sentence, Length: 666, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['label']==0][\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'summary', 'Clustering Layer',\n",
       "       'Supervised Layer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.read_csv(\"D:/NLP/Data/Test_summary_5cluster_2300data.csv\")\n",
    "summary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_summary = summary.loc[:,\"Clustering Layer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Unnamed: 0', 'sentence', 'label'], dtype='object'),\n",
       " 'Clustering Layer')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns, op_summary.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Google it just wanted to kind of ask you regarding field invoices sound like to make payment for a long time it is give me an update on the same. Okay, I see give me a minute. I have 10 invoices pending for payment getting tell me which one was how you talking about. I'm actually talking about the legal services if there was an old invoices. We're open from 3 til reason. Let me check the different days out. So I have 14 voices in the month off.Tuba call back relations. We just need a payment today in the morning. So I think I should be able to expect you like to receive it in and maybe a couple of days. Have a nice day.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train.loc[:,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    666\n",
       "1    198\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = 'glove.840B.300d.txt'\n",
    "MODEL_PATH = '/NLP/InferSent/encoder/infersent1.pickle'\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.set_w2v_path(GLOVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=train['sentence'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, this is John Smith.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentences = preprocess(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello this is john smith'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 779(/781) words with w2v vectors\n",
      "Vocab size : 779\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(clean_sentences, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for i in range(len(clean_sentences)):\n",
    "    #print(i)\n",
    "    embeddings.append(model.encode([clean_sentences[i]], tokenize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07358228,  0.05932116, -0.01329149, ..., -0.03116866,\n",
       "       -0.03814263,  0.10867259], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_features =pd.DataFrame()\n",
    "for i in embeddings:\n",
    "    embedding_features = embedding_features.append(pd.Series(list(i[0])),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_features.to_csv(\"C:/NLP/Data/embedding_features_transcripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_features=pd.read_csv('C:/NLP/Data/Embeddings1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "            ...\n",
       "            4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095],\n",
       "           dtype='int64', length=4096)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding_features, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 4096)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\samadrita.ghosh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "s_model=LogisticRegression()\n",
    "s_model.fit(X_train.iloc[:,:], y_train)\n",
    "proba=s_model.predict_proba(X_test.iloc[:,:])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred=np.where(proba > 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    131\n",
       "1     42\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       133\n",
      "           1       0.74      0.78      0.76        40\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       173\n",
      "   macro avg       0.83      0.85      0.84       173\n",
      "weighted avg       0.89      0.88      0.89       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[122  11]\n",
      " [  9  31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Google it just wanted to kind of ask you regarding field invoices sound like to make payment for a long time it is give me an update on the same. Okay, I see give me a minute. I have 10 invoices pending for payment getting tell me which one was how you talking about. I'm actually talking about the legal services if there was an old invoices. We're open from 3 til reason. Let me check the different days out. So I have 14 voices in the month off.Tuba call back relations. We just need a payment today in the morning. So I think I should be able to expect you like to receive it in and maybe a couple of days. Have a nice day.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "op_summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4096)\n",
      "[1 0 1 1 1 1 1 1 1 0]\n",
      "[0.46235407 0.95919385 0.12660614 0.6524021  0.7012074  0.83115668\n",
      " 0.06495345 0.285025   0.3437336  0.97697969]\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "(6, 4096)\n",
      "[0 1 0 1 0 1]\n",
      "[0.98468111 0.65739082 0.98795823 0.65156582 0.98524245 0.04170872]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "(10, 4096)\n",
      "[1 1 0 1 1 1 1 1 1 0]\n",
      "[0.06016042 0.75360741 0.98838518 0.94588685 0.02180775 0.92645726\n",
      " 0.11483505 0.07092553 0.02234676 0.97697969]\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "(13, 4096)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0.01806722 0.5495103  0.05640715 0.66280786 0.51488472 0.70946572\n",
      " 0.63529669 0.42342071 0.42012622 0.396481   0.02683006 0.80922385\n",
      " 0.25661954]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "(9, 4096)\n",
      "[1 1 1 1 1 1 1 1 0]\n",
      "[0.02826041 0.18087699 0.37022611 0.69368866 0.04821991 0.80981912\n",
      " 0.77855417 0.39789763 0.98569878]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "(15, 4096)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0.01979671 0.17328189 0.03289811 0.52932827 0.60248961 0.28592634\n",
      " 0.01236165 0.93729825 0.12876548 0.15301161 0.05448464 0.10224862\n",
      " 0.10233614 0.06830175 0.0187084 ]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "(9, 4096)\n",
      "[0 1 1 1 1 0 1 1 1]\n",
      "[0.99094182 0.01108596 0.0337987  0.428909   0.52865292 0.9828019\n",
      " 0.82478665 0.87758817 0.3575167 ]\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "cleaned_summaries = []\n",
    "y_pred_list=[]\n",
    "y_prob_list=[]\n",
    "for para in op_summary:\n",
    "    blob = TextBlob(para)\n",
    "    sentences = [item.raw for item in blob.sentences]\n",
    "    clean_sentences = preprocess(sentences)\n",
    "    \n",
    "    embeddings = []\n",
    "    for i in range(len(clean_sentences)):\n",
    "        #print(i)\n",
    "        embeddings.append(model.encode([clean_sentences[i]], tokenize=True))\n",
    "    \n",
    "    embedding_features =pd.DataFrame()\n",
    "    for i in embeddings:\n",
    "        embedding_features = embedding_features.append(pd.Series(list(i[0])),ignore_index=True)\n",
    "    \n",
    "    print(embedding_features.shape)\n",
    "    proba=s_model.predict_proba(embedding_features)[:,0]\n",
    "    y_pred=np.where(proba > 0.95, 0, 1)\n",
    "    print(y_pred)\n",
    "    print(proba)\n",
    "    summ=[]\n",
    "    count = 0\n",
    "    for label in y_pred:\n",
    "        print(label)\n",
    "        if(label == 1):\n",
    "            summ.append(sentences[count])\n",
    "        count=count+1\n",
    "    cleaned_summaries.append(summ)\n",
    "    y_pred_list.append(y_pred)\n",
    "    y_prob_list.append(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Google it just wanted to kind of ask you regarding field invoices sound like to make payment for a long time it is give me an update on the same.', 'I have 10 invoices pending for payment getting tell me which one was how you talking about.', \"I'm actually talking about the legal services if there was an old invoices.\", \"We're open from 3 til reason.\", 'Let me check the different days out.', 'So I have 14 voices in the month off.Tuba call back relations.', 'We just need a payment today in the morning.', 'So I think I should be able to expect you like to receive it in and maybe a couple of days.']\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google it just wanted to kind of ask you regarding field invoices sound like to make payment for a long time it is give me an update on the same. Okay, I see give me a minute. I have 10 invoices pending for payment getting tell me which one was how you talking about. I'm actually talking about the legal services if there was an old invoices. We're open from 3 til reason. Let me check the different days out. So I have 14 voices in the month off.Tuba call back relations. We just need a payment today in the morning. So I think I should be able to expect you like to receive it in and maybe a couple of days. Have a nice day.\n"
     ]
    }
   ],
   "source": [
    "print(op_summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
